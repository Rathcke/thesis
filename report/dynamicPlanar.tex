\section{Dynamic Oracles in Directed Planar Graphs}\label{dynamicPlanar}
In this chapter we show how to extend the oracle from Section \ref{oracle1} to handle
edge weight changes in \textbf{TODO}. We also show how to extend the oracle from Section
\ref{oracle2} to support label changes in expected $O(1)$ time.

\subsection{A dynamic oracle supporting edge weight updates}\label{oracle3}
We now give a dynamic distance oracle that can support edge weight changes, edge
insertions and deletion as well as answering queries in amortized $O(n^{2/3}\lg^{5/3}n)$
time. We assume that no updates will violate the planar embedding of $G$. \\
\\
\indent \textit{Data structure}.
Like the oracle in Section \ref{oracle1}, we construct an $r$-division and maintain a
dense distance graph of all the pieces.  \\

\indent \textit{Edge weight update}.
We simply update the weight of the edge and recompute the dense distance graph in which
the modified edge is. \\
\\
\indent \textit{Edge deletion}.
A deleted edge will always happen entirely within a single piece $P$, so we simply remove
the edge and recompute the dense distance graph of $P$. \\
\\
\indent \textit{Edge insertion}.
There are two cases whenever we insert an edge. If the inserted edge is in a single piece
$P$, we simply insert it. If the endpoints, $x$ and $y$, of the inserted edge belong to two different
pieces, it will violate the property of an $r$-division. That is, any edge going out of
the piece, must go through a boundary vertex. However, we can overcome with by making $x$
a boundary vertex of the piece it belongs to. This will not increase the number of holes,
and we recompute the dense distance graph of $P$. \\
\\
\indent \textit{Query}. To answer the query $Q(u,\lambda)$, we use Djikstra variant
described in Section \ref{frdjikstra}. Since this algorithm answers the query $Q(u,v)$,
we need to keep track of the labels on each vertex we visit and keep track of the minimum
distance to a vertex with label $\lambda$. That is, every time we
extract a vertex with label $\lambda$ from the global heap, we check if it the distance
to it is a new minimum. TODO: Store distances from boundary nodes to nodes in each region
and check total distance.

\subsubsection{Analysis}
\textbf{Preprocessing}.
We can compute an $r$-division in $O(n)$
time. We then
construct a dense distance graph, that is, we construct the graph where each edge $uv\in
E$ has weight equal to $\delta(u,v)$ and $u$ and $v$ are both boundary nodes. We use
Klein's multiple source shortest path algorithm \cite{klein2005multiple} to compute DDG's
for each region of an $r$-division. For each region $R$ with $r$ nodes, we use $O(r\lg
r)$ preprocessing to compute distances $\delta(u,v)$ in $O(\lg r)$ time where either $u$
or $v$ is a boundary node. Since each region has $O(\sqrt{r})$ boundary nodes and $O(1)$
holes, we can compute all distances in $O(r\lg r)$ time. Since there are $O(n/r)$
regions, this yields a total running time of $O(nr\lg r/r)=O(n\lg r)$ to construct the
dense distance graph. \\
\\
\textbf{Space}. \\
\\
\textbf{Query}. \\
\\
\textbf{Updates}.
 Since we recompute the $r$-division after we have
done an order of $\sqrt{r}$ operation, we know that each piece cannot at any time have
more than $O(r)$ edges and $O(\sqrt{r})$ boundary vertices. An amortized analysis over
all $\sqrt{r}$ operations gives us $O(\frac{n+n\lg r}{\sqrt{r}})=O(n\lg r/\sqrt{r})$ for
each graph modification.


\subsection{A dynamic oracle supporting label changes}\label{oracle4}
Recall the oracle described in Section \ref{oracle2}. We now give an oracle that can
handle label changes in $O(1)$ time. Namely, we show the following theorem if we assume
that there are no more than $O(\sqrt{n})$ labels of polynomial size:
\begin{thm}\label{thm3}
  There is an oracle of requiring preprocessing time $O(n^{3/2})$ of size $O(n^{3/2})$ that
  can answer distance queries in $O(\text{polylog}(n))$ time. Furthermore, it can handle
  label changes in expected amortized $O(1)$ time.
\end{thm}
\textit{Data structure}.
The data structure is constructed almost the same way as the one described in Section
\ref{oracle2}, but we modify the hash table used in it and add another one. The added
hash table is used for a simple lookup of what label a vertex has. That is, we use the
vertex number as key and store the label as the information. Note that we can pick our
hash function to avoid any collision (e.g. vertex $v$ \texttt{mod} $n$). Call this hash
table for $h_1$. \\
We also store another hash table keeping track of all vertices with a given label as in
the static case. That is, given a label $\lambda$, we return all vertices with $\lambda$.
We call this hash table for $h_2$. \\
\\
\indent\textit{Update}.
Every time we make a label change, we need to lookup the label in $h_1$ and change
it to the new one. However, since we also need to be able to retrieve all vertices given some label
$\lambda$ (which we obtain from $h_1$) in the query, we need the other hash table to adjust accordingly. This means
removing the vertex from the hash table and inserting in its new hash table location.

\subsubsection{Analysis}
Preprocessing, space and query time follows from the analysis in Section
\ref{oracle2analysis} as it is the same construction. \\
However, we need to analyse the update time. We can easily construct $h_1$ in $O(n)$ time
requiring $O(n)$ space, and since each bucket contains a single element, deletion of the
record  can be done in $O(1)$ time and insertion (of a new label) can be done $O(1)$ time
too. \\
\\
Constructing $h_2$ requires a little more thinking. Each bucket can be expected to
have $n/\ell$ elements, but in worst case they can be up to $O(n)$ in size. Therefore we
need a \textit{dynamic perfect hashing} scheme that supports $O(1)$ lookup and
amortized expected insertion and deletion in constant time. Dietzfelbinger et al.
\cite{dietzfelbinger1994dynamic} introduced a randomized algorithm achieving this. The idea is to use a
primary hash function to construct buckets containing all vertices with the same label.
These buckets are dynamic arrays. We use hashing with chaining for the vertices in each bucket to ensure we have expected lookup in $O(1)$ time. The algorithm keeps track numbers of how many elements are in
each bucket and we refer to these numbers as $b_i$. Each bucket is assigned $s_i$ space,
where $s_i=2b_i$. For each bucket, there is a specified threshold $t_i=(1+c)b_i$ (in this
case, we use $c=1$). When $b_i$ exceeds $t_i$ or falls below
$t_i/(1+2c)$, the array is destroyed and a new (larger or smaller) array is created and
we rehash all elements of the bucket into it in $O(n)$ time. \\
Now lookup can easily be done in $O(1)$ time, since we lookup the label in $h_1$ in
$O(1)$ time. Given the label, we can locate the vertex in $h_2$ in $O(1)$ time as well.
Deletion and insertion (which is what a label change requires) in $h_1$ is done in
expected $O(1)$
time. When we want to delete an element $x$ from $h_2$, we first perform a lookup of $x$
and mark the slot as empty as well as decrementing $b_i$ by one. For insertion, we can
add $x$ to its proper place in expected $O(1)$ time and we increment $b_i$ by one. \\
Since we rarely need to rehash elements into a dynamic array, we achieve the expected amortized
constant update time. First we need to show that we can expect any 'chain' in the array
will have constant size. We hash $b_i$ elements uniformly at random into a table of size
$s_i=2b_i$, thus any chain is expected to have $1/2$ elements - also called the load
factor $\alpha$. When $\alpha$ is $O(1)$, we can also expect constant search, insertion and
deletion \cite{cormen2009introduction}. \\
The space taken by the hash table is $O(n)$, which can be seen by inspecting the size of
each array. The arrays have size $s_i$ which all have size $O(b_i)$, so we get space $S$ is
\begin{align*}
  S&=O\left(\sum_i s_i\right) \\
   &=O\left(\sum_i b_i\right) \\
   &=O(n) \comment{As $\sum_i b_i = n$}
\end{align*}
This will yield the result in Theorem \ref{thm3} 
TODO: Label changes to size $O(\sqrt{n})$ and figure???
